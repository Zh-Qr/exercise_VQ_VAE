{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27912cf3",
   "metadata": {},
   "source": [
    "# VQ-VAE test on MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a20972e",
   "metadata": {},
   "source": [
    "## import dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "142a61df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "from tqdm import tqdm \n",
    "from PIL import Image\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bd6163",
   "metadata": {},
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cf2eef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    data_root: str = \"./data\"\n",
    "    runs_root: str = \"./runs\"\n",
    "    batch_size: int = 128\n",
    "    num_workers: int = 4\n",
    "    epochs: int = 15\n",
    "    lr: float = 1e-4\n",
    "    beta: float = 0.25                # commitment loss 权重\n",
    "    image_size: int = 28\n",
    "    in_channels: int = 1              # MNIST 是单通道\n",
    "    embedding_dim: int = 64           # 码本向量维度 D\n",
    "    num_codes: int = 512              # 码本大小 K\n",
    "    seed: int = 42\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    log_interval: int = 100\n",
    "    save_interval: int = 1\n",
    "\n",
    "\n",
    "cfg = Config()\n",
    "os.makedirs(cfg.runs_root, exist_ok=True)\n",
    "torch.manual_seed(cfg.seed)\n",
    "random.seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f678926",
   "metadata": {},
   "source": [
    "## encoder & decoder module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10595ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    输入: Bx1x28x28 -> 输出: BxDx7x7\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch=1, hidden=128, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, hidden, 4, stride=2, padding=1),  # 28->14\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(hidden, hidden, 3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(hidden, hidden, 4, stride=2, padding=1), # 14->7\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(hidden, embedding_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    输入: BxDx7x7 -> 输出: Bx1x28x28\n",
    "    \"\"\"\n",
    "    def __init__(self, out_ch=1, hidden=128, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(embedding_dim, hidden, 3, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.ConvTranspose2d(hidden, hidden, 4, stride=2, padding=1),  # 7->14\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(hidden, hidden, 3, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.ConvTranspose2d(hidden, out_ch, 4, stride=2, padding=1),  # 14->28\n",
    "            nn.Tanh()  # 因为输入做了 Normalize((0.5,),(0.5,))，目标是 [-1,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c13bfa8",
   "metadata": {},
   "source": [
    "## VectorQuantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed23959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizer(nn.Module):\n",
    "    \"\"\"\n",
    "    - codebook: nn.Embedding(K, D)\n",
    "    - forward:\n",
    "        1) flatten z_e -> (BHW, D)\n",
    "        2) 与 codebook.weight (K, D) 计算 L2 距离，取最近索引\n",
    "        3) 用 embedding 索引回 (BHW, D)，再 reshape 回 BxDxHxW\n",
    "        4) 计算三项损失（recon 在外部），返回 z_q 与 stats\n",
    "    - perplexity:\n",
    "        使用 one-hot 选择的平均分布计算 exp(H(p))\n",
    "    \"\"\"\n",
    "    def __init__(self, num_codes=512, embedding_dim=64, beta=0.25):\n",
    "        super().__init__()\n",
    "        self.num_codes = num_codes\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.beta = beta\n",
    "\n",
    "        self.codebook = nn.Embedding(num_codes, embedding_dim)\n",
    "        # 初始化为均匀分布（推荐：正态或均匀，小尺度）\n",
    "        self.codebook.weight.data.uniform_(-1.0 / num_codes, 1.0 / num_codes)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _compute_distances(self, z_flat):\n",
    "        # z_flat: (N, D); codebook: (K, D)\n",
    "        # ||z - e||^2 = ||z||^2 + ||e||^2 - 2 z·e\n",
    "        z_sq = (z_flat ** 2).sum(dim=1, keepdim=True)            # (N,1)\n",
    "        e_sq = (self.codebook.weight ** 2).sum(dim=1)            # (K,)\n",
    "        ze = z_flat @ self.codebook.weight.t()                   # (N,K)\n",
    "        dist = z_sq + e_sq.unsqueeze(0) - 2 * ze\n",
    "        return dist\n",
    "\n",
    "    def forward(self, z_e):\n",
    "        # z_e: BxDxHxW\n",
    "        B, D, H, W = z_e.shape\n",
    "        assert D == self.embedding_dim\n",
    "\n",
    "        # 1) flatten\n",
    "        z_flat = z_e.permute(0, 2, 3, 1).contiguous().view(-1, D)  # (BHW, D)\n",
    "\n",
    "        # 2) 最近码本索引\n",
    "        with torch.no_grad():\n",
    "            dist = self._compute_distances(z_flat)                 # (BHW, K)\n",
    "            indices = torch.argmin(dist, dim=1)                    # (BHW,)\n",
    "            encodings = F.one_hot(indices, self.num_codes).type(z_flat.dtype)  # (BHW, K)\n",
    "\n",
    "        # 3) 查表回量化向量\n",
    "        z_q_flat = self.codebook(indices)                          # (BHW, D)\n",
    "        z_q = z_q_flat.view(B, H, W, D).permute(0, 3, 1, 2).contiguous()  # BxDxHxW\n",
    "\n",
    "        # 4) straight-through trick: 把 z_q 当作 z_e 的前向，但反向给 z_e 传梯度\n",
    "        # 公式: z_q + (z_e - z_q).detach()\n",
    "        z_q_st = z_e + (z_q - z_e).detach()\n",
    "\n",
    "        # 5) 码本与承诺损失\n",
    "        # codebook loss: ||sg[z_e] - e||^2\n",
    "        codebook_loss = F.mse_loss(z_q.detach(), z_e)\n",
    "        # commitment loss: ||z_e - sg[e]||^2\n",
    "        commitment_loss = F.mse_loss(z_q, z_e.detach())\n",
    "        vq_loss = codebook_loss + self.beta * commitment_loss\n",
    "\n",
    "        # 6) perplexity（衡量码本使用多样性）\n",
    "        avg_probs = encodings.mean(dim=0)                          # (K,)\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "\n",
    "        return z_q_st, vq_loss, indices.view(B, H, W), perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64208686",
   "metadata": {},
   "source": [
    "## VQ-VAE encapsulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53033e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQVAE(nn.Module):\n",
    "    def __init__(self, in_ch=1, embedding_dim=64, num_codes=512, beta=0.25, hidden=128):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(in_ch=in_ch, hidden=hidden, embedding_dim=embedding_dim)\n",
    "        self.quantizer = VectorQuantizer(num_codes=num_codes, embedding_dim=embedding_dim, beta=beta)\n",
    "        self.decoder = Decoder(out_ch=in_ch, hidden=hidden, embedding_dim=embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_e = self.encoder(x)                # 连续潜表示\n",
    "        z_q, vq_loss, indices, ppl = self.quantizer(z_e)  # 量化\n",
    "        x_rec = self.decoder(z_q)            # 重建\n",
    "        return x_rec, vq_loss, indices, ppl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e94f899",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61f16fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(batch_size=128, num_workers=4):\n",
    "    tfm = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),  # Convert to grayscale to match input channels\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1] range\n",
    "    ])\n",
    "    train_set = datasets.MNIST(root=cfg.data_root, train=True, download=True, transform=tfm)\n",
    "    test_set  = datasets.MNIST(root=cfg.data_root, train=False, download=True, transform=tfm)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=num_workers, pin_memory=True)\n",
    "    test_loader  = DataLoader(test_set, batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=num_workers, pin_memory=True)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9653661",
   "metadata": {},
   "source": [
    "## train & eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46566b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_reconstructions(model, loader, epoch, device, max_samples=16):\n",
    "    model.eval()\n",
    "    x, _ = next(iter(loader))\n",
    "    x = x.to(device)[:max_samples]\n",
    "    with torch.no_grad():\n",
    "        x_rec, _, _, _ = model(x)\n",
    "\n",
    "    # 保证可视化范围正确\n",
    "    x_vis = torch.clamp(x.detach().cpu(), 0.0, 1.0)\n",
    "    xrec_vis = torch.clamp(x_rec.detach().cpu(), 0.0, 1.0)\n",
    "\n",
    "    # 分别做成单行网格，再上下拼接成最终图片\n",
    "    top = utils.make_grid(x_vis, nrow=max_samples, padding=2)\n",
    "    bottom = utils.make_grid(xrec_vis, nrow=max_samples, padding=2)\n",
    "    grid = torch.cat([top, bottom], dim=1)  # dim=1 表示按高度方向拼接\n",
    "\n",
    "    save_path = os.path.join(cfg.runs_root, f\"recon_epoch_{epoch:02d}.png\")\n",
    "    utils.save_image(grid, save_path)\n",
    "    print(f\"[Eval] Saved reconstructions to {save_path}\")\n",
    "    # 便于排查：打印数值范围\n",
    "    print(f\"[Debug] x    range: [{x_vis.min():.3f}, {x_vis.max():.3f}]\")\n",
    "    print(f\"[Debug] x_rec range: [{xrec_vis.min():.3f}, {xrec_vis.max():.3f}]\")\n",
    "\n",
    "\n",
    "def train():\n",
    "    device = cfg.device\n",
    "    train_loader, test_loader = get_loaders(cfg.batch_size, cfg.num_workers)\n",
    "\n",
    "    model = VQVAE(\n",
    "        in_ch=cfg.in_channels,\n",
    "        embedding_dim=cfg.embedding_dim,\n",
    "        num_codes=cfg.num_codes,\n",
    "        beta=cfg.beta,\n",
    "    ).to(device)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "\n",
    "    global_step = 0\n",
    "    for epoch in range(1, cfg.epochs + 1):\n",
    "        model.train()\n",
    "        running = {\"recon\": 0.0, \"vq\": 0.0, \"ppl\": 0.0}\n",
    "\n",
    "        # 用 tqdm 包装 dataloader\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch}/{cfg.epochs}\")\n",
    "        for i, (x, _) in pbar:\n",
    "            x = x.to(device)\n",
    "\n",
    "            x_rec, vq_loss, _, ppl = model(x)\n",
    "            recon_loss = F.l1_loss(x_rec, x)  # L1 重建\n",
    "            loss = recon_loss + vq_loss\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            running[\"recon\"] += recon_loss.item()\n",
    "            running[\"vq\"] += vq_loss.item()\n",
    "            running[\"ppl\"] += ppl.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # 更新进度条后缀\n",
    "            avg_recon = running[\"recon\"] / (i + 1)\n",
    "            avg_vq    = running[\"vq\"] / (i + 1)\n",
    "            avg_ppl   = running[\"ppl\"] / (i + 1)\n",
    "            pbar.set_postfix({\n",
    "                \"Recon\": f\"{avg_recon:.4f}\",\n",
    "                \"VQ\": f\"{avg_vq:.4f}\",\n",
    "                \"Perplexity\": f\"{avg_ppl:.2f}\"\n",
    "            })\n",
    "\n",
    "        # 每轮保存重建可视化\n",
    "        if epoch % cfg.save_interval == 0 or epoch == cfg.epochs:\n",
    "            save_reconstructions(model, test_loader, epoch, device)\n",
    "\n",
    "            # 保存权重\n",
    "            ckpt_path = os.path.join(cfg.runs_root, f\"vqvae_epoch_{epoch:02d}.pt\")\n",
    "            torch.save({\"model\": model.state_dict(), \"cfg\": cfg.__dict__}, ckpt_path)\n",
    "            print(f\"[Save] checkpoint to {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5e917f",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2547526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|██████████| 469/469 [02:12<00:00,  3.53it/s, Recon=0.9800, VQ=7.9405, Perplexity=0.00] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Eval] Saved reconstructions to ./runs\\recon_epoch_01.png\n",
      "[Debug] x    range: [0.000, 1.000]\n",
      "[Debug] x_rec range: [0.000, 0.002]\n",
      "[Save] checkpoint to ./runs\\vqvae_epoch_01.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15:   7%|▋         | 35/469 [00:12<02:37,  2.75it/s, Recon=0.9452, VQ=0.0006, Perplexity=0.00]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 108\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    105\u001b[0m loss \u001b[38;5;241m=\u001b[39m recon_loss \u001b[38;5;241m+\u001b[39m vq_loss\n\u001b[0;32m    107\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 108\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    111\u001b[0m running[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecon\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m recon_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
